<!DOCTYPE html>
<html>
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PR39LSGTSL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-PR39LSGTSL');
  </script>
  
  <meta charset="utf-8">
  <meta name="description"
        content="Coordination of Learned Decoupled Dual-Arm Tasks through Gaussian
        Belief Propagation">
  <meta name="keywords" content="Robot, LLM, Planning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Coordination of Learned Decoupled Dual-Arm Tasks through Gaussian
    Belief Propagation</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js"></script>
  
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item">
        <span class="icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"> <path fill="#808080" d="M320 0c17.7 0 32 14.3 32 32V96H472c39.8 0 72 32.2 72 72V440c0 39.8-32.2 72-72 72H168c-39.8 0-72-32.2-72-72V168c0-39.8 32.2-72 72-72H288V32c0-17.7 14.3-32 32-32zM208 384c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16H208zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16H304zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16H400zM264 256a40 40 0 1 0 -80 0 40 40 0 1 0 80 0zm152 40a40 40 0 1 0 0-80 40 40 0 1 0 0 80zM48 224H64V416H48c-26.5 0-48-21.5-48-48V272c0-26.5 21.5-48 48-48zm544 0c26.5 0 48 21.5 48 48v96c0 26.5-21.5 48-48 48H576V224h16z"/></svg>      
        </span>
        </a>
  
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://github.com/AdrianPrados/Robotic-Rearrangement-of-Everyday-Objects" target="_blank">
              Robotic Rearrangement of Everyday Objects
            </a>
            <a class="navbar-item" href="https://github.com/AdrianPrados/Learning-and-generalization-of-task-parameterized-skills-through-few-human-demonstrations" target="_blank">
              Learning and Generalization of Task Parameterized Skills Through Few Human Demonstrations
            </a>
          </div>
        </div>
      </div>
    </div>
  </nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <img src="static/images/logo-iros.png" alt="iros-25" style="width:160px;height:auto;">
          <h1 class="title is-1 publication-title">Coordination of Learned Decoupled Dual-Arm Tasks through Gaussian
            Belief Propagation</h1>
          <div class="is-size-5 publication-authors">

            <span class="author-block">
              <a href="https://github.com/AdrianPrados" target="_blank"> Adrian Prados,</a>
            </span>

            <span class="author-block">
              <a href="https://github.com/gonecho" target="_blank"> Gonzalo Espinoza,</a>
            </span>

            <span class="author-block">
              <a href="https://scholar.google.es/citations?user=FHOCQnUAAAAJ&hl=es" target="_blank"> Luis Moreno,</a>
            </span>

            <span class="author-block">
              <a href="https://scholar.google.es/citations?user=zVLybhsAAAAJ&hl=es" target="_blank"> Ramon Barber</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <a class="author-block" href="https://mobile-robots-group-uc3m.github.io/MobileRobotsDocumentation/" target="_blank">Mobile Robots Group, RoboticsLab, University Carlos III</a>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <!--<span class="link-block">
                <a href="https://arxiv.org/abs/2403.12533" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>-->

              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/4wB8RAer-kw"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> 

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/AdrianPrados/GaussianBeliefPropagationDualArm"
                   class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>GitHub</span>
                </a>
              </span>

              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero body">
  <div class="container is-max-desktop">
    <img src="./static/images/EsquemaGeneral.jpg">
    <h2 class="subtitle has-text-centered">
      General scheme of the proposed algorithm for coordinating decoupled tasks through learning the tasks for each arm 
      independently and subsequently coordinating them using Gaussian Belief Propagation.
    </h2>
  </div>
</section>

<!-- Abstract. -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Robotic manipulation can involves multiple manipulators to complete a task. 
            In those cases, the complexity of performing the task in a coordinated manner increases, requiring coordinated planning while avoiding collisions between robots and environmental elements. 
            For these challenges, we propose a robotic arm control algorithm based on Learning from Demonstration to independently learn the tasks of each arm, followed by a graph-based communication method using Gaussian Belief Propagation. 
            Our method enables the resolution of decoupled dual-arm tasks learned independently without requiring coordinated planning. 
            The algorithm generates smooth, collision-free solutions between arms and environmental obstacles while ensuring efficient movements without the need for constant replanning. 
            Its efficiency has been validated through experiments and comparisons against another multi-robot control method in simulation using PyBullet with two opposing IIWA robots, as well as a mobile robot with two UR3 arms, which has also been used for real-world testing.
          </p>
        </div>
      </div>
    </div>
  </div>
  <br>
  <!--<div class="container is-max-desktop">
    <div class="hero body">
      <video id="teaser" autoplay="autoplay" controls autoplay muted loop playsinline height="100%">
        <source src="./static/videos/IROS24-website.mp4" type="video/mp4">
      </video>
      <p class="subtitle has-text-centered">
        ADRI AQUI METE EL VIDEO
      </p>
    </div>
  </div>-->
</section>



<!-- System. -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Method Description</h2>
        <div class="content has-text-justified">
          <p>
            Our algorithm is designed to coordinate dual-arm tasks in decoupled scenarios. 
            It consists of two main modules: a Learning from Demonstration (LfD) module that enables each robotic arm to independently 
            learn its task using kinesthetic demonstrations and a Task-Parameterized Gaussian Mixture Model (TP-GMM), and a collaborative control module based 
            on Gaussian Belief Propagation (GBP) that dynamically synchronizes the end-effectors. This second module communicates between the two arms to 
            ensure safe, collision-free movements while adapting in real time to obstacles and dynamic changes in the environment. 
            The approach has been validated through extensive simulation and real-world experiments, demonstrating improvements in execution time, 
            path efficiency, and motion smoothness compared to state-of-the-art methods.
          </p>
        </div>
      </div>
    </div>
    <div class="column">
      <img src="./static/images/IntroPaper.jpg">
      <p class="subtitle has-text-centered">
        The method presented in this work independently learns to solve a task for each arm. 
        These tasks are then coordinated through the application of a new method based on Gaussian Belief Propagation, 
        which enables coordination while simultaneously avoiding obstacles in the environment by using the learned paths.
      </p>
    </div>
    <div class="content has-text-justified">
      <p>
        Our algorithm is composed of two main modules: the learning module and the coordination module using Gaussian Belief Propagation (GBP).


        In the learning phase, each arm independently learns its task through kinesthetic demonstrations. During these demonstrations, 
        the positions and orientations of the end-effector are recorded in a task-related reference frame. 
        Then, using a task-parameterized Gaussian Mixture Model (TP-GMM), the invariant structure of the task is extracted. 
        To optimize the model’s accuracy, synthetic data is iteratively generated and integrated only if it improves the solution. 
        In this way, the algorithm can learn a representative trajectory from a limited set of demonstrations.
        
        Once each arm has learned its task, GBP is used to coordinate their movements in real time. 
        In this module, each state of the end-effector is represented as a variable in a factor graph. 
        The factors model the dynamic constraints, the presence of obstacles, and the interactions between the two arms. 
        Through an iterative message-passing process, GBP enables the arms to share information about their positions and velocities, 
        adjusting their trajectories to avoid collisions and ensure smooth, synchronized execution. 
      </p>
    </div>
  </div>
</section>

<!-- Examples of the method. -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Simulated Examples in PyBullet</h2>
        <div class="content has-text-justified">
          <p>
            Below, different examples of the algorithm's functionality in simulated environments are presented. 
            These examples demonstrate the algorithm's efficiency with two opposing IIWA robots. 
            In each case, a critical scenario is presented—these are situations where the robot's movements intersect with each other or cross obstacles 
            in the environment. 
            In all cases, the algorithm successfully resolves the movements efficiently without colliding with environmental elements or the other arm.
          </p>
        </div>
      </div>
      <div class="column">
        <img src="./static/images/ResultIIWA.jpg">
        <p class="subtitle has-text-centered">
          Results of the different experiments conducted with the IIWA robots in simulation in terms of movement smoothness, 
          analyzing velocity and position.
        </p>
      </div>
      <div class="content has-text-justified">
    </div>
  </div>

  <!-- Video Section -->
  <div class="container">
    <div class="columns is-multiline is-centered">
      
      <!-- Video 1 -->
      <div class="column is-one-quarter">
        <figure class="image is-16by9">
          <video controls>
            <source src="./static/videos/Exp1IIWA.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </figure>
        <p class="has-text-centered">Example 1: Opposite movements without obstacles.</p>
      </div>

      <!-- Video 2 -->
      <div class="column is-one-quarter">
        <figure class="image is-16by9">
          <video controls>
            <source src="./static/videos/Exp2IIWA.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </figure>
        <p class="has-text-centered">Example 2: Opposite movements with 1 obstacles.</p>
      </div>

      <!-- Video 3 -->
      <div class="column is-one-quarter">
        <figure class="image is-16by9">
          <video controls>
            <source src="./static/videos/Exp3IIWA.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </figure>
        <p class="has-text-centered">Example 3: Opposite movements with 5 obstacles (narrow passage).</p>
      </div>

      <!-- Video 4 -->
      <div class="column is-one-quarter">
        <figure class="image is-16by9">
          <video controls>
            <source src="./static/videos/Exp4IIWA.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </figure>
        <p class="has-text-centered">Example 4: Obstacle in final point.</p>
      </div>

    </div>
  </div>

</section>


<!-- Examples with ADAM. -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Examples in Real Environments with ADAM</h2>
        <div class="content has-text-justified">
          <p>
            The algorithm has also been used for tasks in real environments using the ADAM robot, 
            belonging to the Mobile Robotics group at RoboticsLab, at the Carlos III University of Madrid. 
            In these tests, two real task experiments were conducted where coordination between the two robotic arms is crucial: 
            a cube stacking task and a shelf organization task. In this case, each arm uses a trajectory learned 
            through Learning from Demonstration completely independently, without considering the other arm at any moment. 
            The developed algorithm will handle the necessary coordination. The following two videos demonstrate the efficiency of 
            our algorithm on the real platform, performing complex tasks smoothly and always achieving a satisfactory result.
          </p>
        </div>
      </div>
    </div>
  </div>

  <!-- Video Section -->
  <div class="container">
    <div class="columns is-centered">
      
      <!-- Video 1 -->
      <div class="column is-half">
        <figure class="image is-16by9">
          <video controls>
            <source src="./static/videos/CubosRealADAM.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </figure>
        <p class="has-text-centered">Cube stacking task.</p>
      </div>

      <!-- Video 2 -->
      <div class="column is-half">
        <figure class="image is-16by9">
          <video controls>
            <source src="./static/videos/ColocarLatasRealADAM.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </figure>
        <p class="has-text-centered">Shelf organization task.</p>
      </div>

    </div>
  </div>

</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template">Academic Project Page Template.
          </p>
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
<script>hljs.highlightAll();</script>
